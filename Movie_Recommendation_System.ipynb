{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Movie Recommendation System using Collaborative Filtering Model\n"
      ],
      "metadata": {
        "id": "FjLcv4DWnu6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Download the MovieLens Dataset"
      ],
      "metadata": {
        "id": "t9veLkgfqHYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Before you start the project -  downaload the MovieLens dataset \"https://grouplens.org/datasets/movielens/\"\n",
        "# Download the latest version of ML Dataset: \"ml-latest-small\""
      ],
      "metadata": {
        "id": "qPjK3zh1oAw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Install all the necessary Libraries"
      ],
      "metadata": {
        "id": "tUhcpc55Xc1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ph9yoxDgVx83",
        "outputId": "f9cd545c-6346-4d8e-cfbe-77e5b2d7f170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: surprise in /usr/local/lib/python3.10/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.10/dist-packages (from surprise) (1.1.3)\n",
            "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise->surprise) (1.10.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Import the necessary libraries"
      ],
      "metadata": {
        "id": "DUAREwFAqTZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas for\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import accuracy\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "js7cybB2mBGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fun Fact about Pandas:** Pandas is a popular Python library used for ***data manipulation and analysis***. It provides high-performance, easy-to-use data structures and data analysis tools for handling structured data. Pandas was created in 2008 by Wes McKinney while he was working at AQR Capital Management. McKinney created Pandas to address the limitations of the tools available for data analysis and manipulation in Python at the time.\n",
        "\n",
        "**Fun Fact about Numpy:** NumPy is a popular Python library used for ***scientific computing and numerical analysis***. It provides high-performance multidimensional array objects and tools for working with these arrays. NumPy was created in 2005 by Travis Oliphant, a Python developer and data scientist. Oliphant created NumPy to address the limitations of the tools available for scientific computing and numerical analysis in Python at the time.\n",
        "\n",
        "**Fun Fact about Scikit-Learn:** Scikit-Learn, also known as sklearn, is a popular Python library used for ***machine learning tasks***. It provides a range of tools for data preprocessing, model selection, and model evaluation, as well as a variety of machine learning algorithms. Scikit-Learn was created in 2007 by David Cournapeau as part of the Google Summer of Code program. Since then, it has been developed and maintained by a team of developers.\n",
        "\n",
        "**Fun Fact about Surprise:** Surprise is a Python library for ***building and analyzing recommender systems***. It was created in 2014 by Nicolas Hug.\n",
        "Surprise is designed to provide easy and efficient implementation of collaborative filtering algorithms, which are commonly used for recommender systems. It offers a range of built-in algorithms for matrix factorization, neighborhood-based methods, and other recommendation approaches."
      ],
      "metadata": {
        "id": "lXDY21iNozvN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Load the Data\n"
      ],
      "metadata": {
        "id": "qOfBaZf5qgjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the \"movies.csv\" and \"ratings.csv\" files into pandas dataframe\n",
        "movies=pd.read_csv('/content/drive/MyDrive/ml-latest-small/movies.csv')\n",
        "ratings=pd.read_csv('/content/drive/MyDrive/ml-latest-small/ratings.csv')"
      ],
      "metadata": {
        "id": "TuTp5UromeQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Preprocess the Data"
      ],
      "metadata": {
        "id": "Tkt6YYPWq2Q2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Surprise library expects the data in a specific format so we need to customise according to that.\n",
        "# We create a Reader object that tells Surprise how to parse the data and then load the data into the Surprise dataset format.\n",
        "reader = Reader(rating_scale=(0.5,5))\n",
        "data_ratings=Dataset.load_from_df(ratings[['userId','movieId','rating']],reader)"
      ],
      "metadata": {
        "id": "Y-m2e7hSnX06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Slit the Data into Train and Test"
      ],
      "metadata": {
        "id": "cyAH3lqyNlbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We split the dataset into training and testing\n",
        "trainset_ratings, testset_ratings = train_test_split(data_ratings, test_size=0.2)"
      ],
      "metadata": {
        "id": "BaRS_PLSZ8dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Train for Collaborative Filtering Model"
      ],
      "metadata": {
        "id": "EKxqBaFraUh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We will now train the SVD algorithm on the training dataset.\n",
        "algo=SVD()\n",
        "algo.fit(trainset_ratings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_bUc4RMaeLn",
        "outputId": "ef653e76-82c7-45f2-b699-5632fe87aca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x7feb4604d4e0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Why are we using SVD:*** SVD (Singular Value Decomposition) is a linear algebra algorithm commonly used in recommendation systems for collaborative filtering. SVD is used to factorize a large user-item interaction matrix into smaller matrices of latent features that represent the relationships between users and items. The latent features are learned from the user-item interactions in the training data, and can be used to predict how a user would rate an item they have not yet interacted with. Overall, SVD is a widely used algorithm for collaborative filtering in recommendation systems due to its effectiveness, flexibility, and scalability."
      ],
      "metadata": {
        "id": "1Fcz_uHJbSvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8: Generate Movie Recommendations"
      ],
      "metadata": {
        "id": "RWJ0Kg1wbBr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Once the model is trained - it can be used to generate movie recommendations for a specific user.\n",
        "\n",
        "def fetch_unseen_movies(user_id):\n",
        "  seen_movies = ratings[ratings['userId'] == user_id]['movieId'].tolist()\n",
        "  all_movies = ratings['movieId'].unique().tolist()\n",
        "  unseen_movies = [movie for movie in all_movies if movie not in seen_movies]\n",
        "  return unseen_movies\n",
        "\n",
        "\n",
        "# Lets try generating recommendation for a specific user\n",
        "\n",
        "user_id=1\n",
        "unseen_movies = fetch_unseen_movies(user_id)\n",
        "testset_ratings = [[user_id, movie_id, 4.0] for movie_id in unseen_movies]\n",
        "predictions = algo.test(testset_ratings)\n",
        "\n",
        "\n",
        "# Lets try to get the top-N recommendations\n",
        "def get_top_n_recommendations(predictions, n):\n",
        "  top_n = defaultdict(list)\n",
        "  for uid,iid,true_r,est, _ in predictions:\n",
        "    top_n[uid].append((iid,est))\n",
        "  for uid, ratings in top_n.items():\n",
        "    ratings.sort(key=lambda x:x[1], reverse=True)\n",
        "    top_n[uid]=ratings[:n]\n",
        "  return top_n\n",
        "\n",
        "n = 10\n",
        "top_n=get_top_n_recommendations(predictions,n)\n",
        "\n",
        "print(top_n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcoZ-_5Ua_Os",
        "outputId": "a70d6a98-063d-4a41-b320-f90d0bcba300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'list'>, {1: [(318, 5), (58559, 5), (912, 5), (1250, 5), (1252, 5), (1276, 5), (1221, 5), (38061, 5), (1921, 5), (308, 5)]})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9: Evaluate the model\n",
        "\n"
      ],
      "metadata": {
        "id": "sRPtLwQMlm9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can evaluate the performance of the model using RMSE (root mean square error) and MAE (mean absolute error).\n",
        "# The RMSE (root mean squared error) measures the average deviation of the predicted ratings from the actual ratings, while the MAE (mean absolute error) measures the average absolute deviation of the predicted ratings from the actual ratings.\n",
        "# Lower values for both metrics indicate better performance of the model.\n",
        "rmse_score=accuracy.rmse(predictions)\n",
        "mae_score=accuracy.mae(predictions)\n",
        "percentage_accuracy = (1 - rmse_score) * 100\n",
        "print(percentage_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgJjqJmgmTR_",
        "outputId": "31dfc616-ef43-4166-d1d7-0977f9756b72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 0.3023\n",
            "MAE:  0.2467\n",
            "69.76700383480015\n"
          ]
        }
      ]
    }
  ]
}